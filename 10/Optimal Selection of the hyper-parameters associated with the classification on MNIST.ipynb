{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Optimal Selection of the hyper-parameters associated with the classification on MNIST.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMe19ke8W5BHNn1L+liMJzM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"O1305PAEniJS"},"source":["# 0. Setting\n","<hr>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ZjRuljDPm4ML","executionInfo":{"status":"ok","timestamp":1606311378156,"user_tz":-540,"elapsed":4999,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"c38e272b-bdd0-48c7-ba99-cac70981077e"},"source":["# import library\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import math\n","from pandas import Series, DataFrame\n","import pandas as pd\n","import numpy as np\n","\n","torch.__version__\n"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.7.0+cu101'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"QPJ7yRhanyqJ"},"source":["# 1. Data\n","<hr>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0I9AxJjnzpe","executionInfo":{"status":"ok","timestamp":1606322453044,"user_tz":-540,"elapsed":2400,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"03b6bd7a-6abd-4633-b398-8c5b4f1118dd"},"source":["from torchvision import transforms, datasets\n","\n","data_path = './MNIST'\n","\n","data_train  = datasets.MNIST(root = data_path, train= False, download=True)\n","data_test = datasets.MNIST(root = data_path, train= True, download=True)\n","\n","data_train_mean = data_train.data.float().mean()/255\n","data_train_std = data_train.data.float().std()/255\n","\n","data_test_mean = data_test.data.float().mean()/255\n","data_test_std = data_test.data.float().std()/255\n","\n","\n","print(\"train data mean = {}, std = {}\".format(data_train_mean, data_train_std))\n","print(\"test data mean = {}, std = {}\".format(data_test_mean, data_test_std))\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,),(0.3081,)),  # mean value = 0.1307, standard deviation value = 0.3081\n","])\n","\n","'''\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((data_train_mean,),(data_train_std,)),\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((data_test_mean,),(data_test_std,)),\n","])\n","'''\n","\n","data_train  = datasets.MNIST(root = data_path, train= False, download=True, transform= transform)\n","data_test   = datasets.MNIST(root = data_path, train= True, download=True, transform= transform)\n","\n","print(\"the number of your training data (must be 10,000) = \", data_train.__len__())\n","print(\"hte number of your testing data (must be 60,000) = \", data_test.__len__())\n"],"execution_count":44,"outputs":[{"output_type":"stream","text":["train data mean = 0.1325146108865738, std = 0.3104802668094635\n","test data mean = 0.13066047430038452, std = 0.30810779333114624\n","the number of your training data (must be 10,000) =  10000\n","hte number of your testing data (must be 60,000) =  60000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MeGoRsbdyU35"},"source":["# 2.Model\n","<hr>"]},{"cell_type":"code","metadata":{"id":"veKdDvFAoUpW","executionInfo":{"status":"ok","timestamp":1606328433697,"user_tz":-540,"elapsed":916,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}}},"source":["def init_weights_xaiver(m):\n","  if type(m) == nn.Linear:\n","    nn.init.xavier_normal_(m.weight.data)\n","    m.bias.data.fill_(0)\n","\n","def init_weights_he(m):\n","  if type(m) == nn.Linear:\n","    nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","    m.bias.data.fill_(0)\n","\n","class classification(nn.Module):\n","\n","    def __init__(self):\n","        super(classification, self).__init__()\n","        \n","        # construct layers for a neural network\n","        self.classifier1 = nn.Sequential(\n","            nn.Linear(in_features=28*28, out_features=20*20),\n","            nn.ReLU(),\n","            #nn.Sigmoid(),\n","            #nn.Tanh()\n","            #nn.LeakyReLU(),\n","            nn.Dropout(0.15)\n","        ) \n","        self.classifier2 = nn.Sequential(\n","            nn.Linear(in_features=20*20, out_features=10*10),\n","            nn.ReLU(),\n","            #nn.Sigmoid()\n","            #nn.Tanh()\n","            #nn.LeakyReLU(),\n","            nn.Dropout(0.15)\n","        ) \n","        self.classifier3 = nn.Sequential(\n","            nn.Linear(in_features=10*10, out_features=10),\n","            nn.LogSoftmax(dim=1)\n","        ) \n","\n","        self.classifier1.apply(init_weights_he)\n","        self.classifier2.apply(init_weights_he)\n","        self.classifier3.apply(init_weights_he)\n","        \n","    def forward(self, inputs):                 # [batchSize, 1, 28, 28]\n","        x = inputs.view(inputs.size(0), -1)    # [batchSize, 28*28]\n","        x = self.classifier1(x)                # [batchSize, 20*20]\n","        x = self.classifier2(x)                # [batchSize, 10*10]\n","        out = self.classifier3(x)              # [batchSize, 10]\n","        \n","        return out\n"],"execution_count":59,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23655Ihs0RKc"},"source":["# 3. Loss Function\n","<hr>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03QBZh2w0Yas","executionInfo":{"status":"ok","timestamp":1606311402967,"user_tz":-540,"elapsed":1502,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"3e2e0997-9715-475a-b36d-c75728db35ef"},"source":["model = classification()\n","criterion = nn.CrossEntropyLoss()\n","train_y_pred = model(data_train.data.float())\n","train_y = data_train.targets\n","temp_loss = criterion(train_y_pred, train_y)\n","print(temp_loss.data.item())"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2.3054168224334717\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JwiFEFM95eJF"},"source":["#4. Optimization\n","<hr>"]},{"cell_type":"markdown","metadata":{"id":"6v9CS0zo5i9s"},"source":["Define Train Function"]},{"cell_type":"code","metadata":{"id":"7h4nHZPm4fkd","executionInfo":{"status":"ok","timestamp":1606311404582,"user_tz":-540,"elapsed":931,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}}},"source":["def train(model, criterion, train_loader, optimizer, batch_size):\n","  \n","  model.train()\n","  loss_sum = 0\n","  acc_sum = 0\n","  iteration = 0\n","  for xs, ts in iter(train_loader):\n","\n","    iteration = iteration + 1\n","    optimizer.zero_grad()\n","    y_pred = model(xs)\n","    loss = criterion(y_pred, ts)\n","    loss.backward()\n","    optimizer.step()\n","    \n","    loss_sum = loss_sum + float(loss)\n","    zs = y_pred.max(1, keepdim=True)[1] # first column has actual prob\n","    acc_sum = acc_sum + zs.eq(ts.view_as(zs)).sum().item()/batch_size\n","  \n","  loss_avg = math.trunc(loss_sum/iteration * 100) / 100\n","  acc_avg = math.trunc(acc_sum/iteration * 100) / 100\n","  \n","  return loss_avg, acc_avg"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"de1nl9VR5rMS"},"source":["Define Test Function"]},{"cell_type":"code","metadata":{"id":"rJsJjiq95sLq","executionInfo":{"status":"ok","timestamp":1606311406752,"user_tz":-540,"elapsed":1219,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}}},"source":["def test(model,criterion, test_loader, batch_size):\n","  model.eval()\n","  loss_sum = 0\n","  acc_sum = 0\n","  iteration = 0\n","  with torch.no_grad():\n","    for xs, ts in iter(test_loader):\n","      iteration = iteration + 1\n","      y_pred = model(xs)\n","      loss_sum = loss_sum + criterion(y_pred, ts).data.item()\n","      zs = y_pred.max(1, keepdim=True)[1]\n","      acc_sum = acc_sum + zs.eq(ts.view_as(zs)).sum().item()/batch_size\n","  \n","  loss_avg = math.trunc(loss_sum/iteration * 100) / 100\n","  acc_avg = math.trunc(acc_sum/iteration * 100) / 100\n","  \n","  return loss_avg, acc_avg"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nPqKhHnd5s1X"},"source":["Define Gradient Descent Fucntion"]},{"cell_type":"code","metadata":{"id":"HyNaBrP65ynC","executionInfo":{"status":"ok","timestamp":1606311408104,"user_tz":-540,"elapsed":924,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}}},"source":["def gradient_descent(model, optimizer, criterion, batch_size, num_epochs):\n","\n","  # batching\n","  train_loader = torch.utils.data.DataLoader(\n","      data_train,\n","      batch_size=batch_size,\n","      num_workers=2,\n","      shuffle=True,\n","      drop_last=True)\n","  \n","  test_loader = torch.utils.data.DataLoader(\n","      data_test,\n","      batch_size=batch_size,\n","      num_workers=2,\n","      shuffle=False,\n","      drop_last=True)\n","  \n","  \n","  # return variables\n","  train_loss_list, train_acc_list = [], []\n","  test_loss_list, test_acc_list = [], []\n","\n","  \n","  # run training & testing\n","  for epoch in range(num_epochs + 1):\n","\n","    train_loss_avg, train_acc_avg = train(model, criterion, train_loader, optimizer, batch_size)\n","    test_loss_avg, test_acc_avg = test(model, criterion, test_loader, batch_size)\n","    \n","    # add loss and accuracy data\n","    train_loss_list.append(train_loss_avg)\n","    train_acc_list.append(train_acc_avg)\n","    test_loss_list.append(test_loss_avg)\n","    test_acc_list.append(test_acc_avg)\n","\n","    # print\n","    if epoch % 10 != 0 :\n","      continue\n","\n","    print(\"epoch : \", epoch, \" -------------------------------------- \")\n","    print(\"train loss : {}      accuracy = {}\".format(train_loss_avg, train_acc_avg))\n","    print(\"test loss : {}       accuracy = {}\".format(test_loss_avg, test_acc_avg))\n","\n","\n","  return train_loss_list, train_acc_list, test_loss_list, test_acc_list\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3QImPnsICBo_"},"source":["# 5. Select Hyperparameter & Modify/Test Model\n","<hr>"]},{"cell_type":"markdown","metadata":{"id":"oYy4jUrbCSDu"},"source":["size of the mini-batch : 64\n","<br>optimization algorithm : SGD\n","<br>loss funtion : cross entropy\n","<br>regularization algorithm : -\n","<br>learning rate : constant"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQ5mo1RRB3E1","executionInfo":{"status":"ok","timestamp":1606193660307,"user_tz":-540,"elapsed":3879138,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"84d0a110-ea97-4694-bbfd-e598bb41c102"},"source":["# model\n","model = classification()\n","\n","# mini-batch size\n","batch_size = 32\n","\n","# num of epochs\n","num_epochs = 200\n","\n","# learning rate\n","learning_rate = 0.01\n","\n","# optimizer\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n","\n","# loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# run\n","train_loss_list1, train_acc_list1, test_loss_list1, test_acc_list1 = gradient_descent(model, optimizer, criterion, batch_size, num_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch :  0  -------------------------------------- \n","train loss : 2.302      accuracy = 0.146\n","test loss : 2.288       accuracy = 0.136\n","epoch :  10  -------------------------------------- \n","train loss : 2.023      accuracy = 0.761\n","test loss : 2.018       accuracy = 0.753\n","epoch :  20  -------------------------------------- \n","train loss : 1.843      accuracy = 0.821\n","test loss : 1.846       accuracy = 0.808\n","epoch :  30  -------------------------------------- \n","train loss : 1.761      accuracy = 0.845\n","test loss : 1.769       accuracy = 0.828\n","epoch :  40  -------------------------------------- \n","train loss : 1.713      accuracy = 0.86\n","test loss : 1.722       accuracy = 0.845\n","epoch :  50  -------------------------------------- \n","train loss : 1.681      accuracy = 0.872\n","test loss : 1.691       accuracy = 0.858\n","epoch :  60  -------------------------------------- \n","train loss : 1.657      accuracy = 0.882\n","test loss : 1.669       accuracy = 0.866\n","epoch :  70  -------------------------------------- \n","train loss : 1.639      accuracy = 0.888\n","test loss : 1.652       accuracy = 0.871\n","epoch :  80  -------------------------------------- \n","train loss : 1.626      accuracy = 0.893\n","test loss : 1.64       accuracy = 0.876\n","epoch :  90  -------------------------------------- \n","train loss : 1.615      accuracy = 0.897\n","test loss : 1.629       accuracy = 0.879\n","epoch :  100  -------------------------------------- \n","train loss : 1.606      accuracy = 0.9\n","test loss : 1.621       accuracy = 0.882\n","epoch :  110  -------------------------------------- \n","train loss : 1.599      accuracy = 0.905\n","test loss : 1.614       accuracy = 0.885\n","epoch :  120  -------------------------------------- \n","train loss : 1.593      accuracy = 0.907\n","test loss : 1.608       accuracy = 0.887\n","epoch :  130  -------------------------------------- \n","train loss : 1.587      accuracy = 0.91\n","test loss : 1.603       accuracy = 0.889\n","epoch :  140  -------------------------------------- \n","train loss : 1.581      accuracy = 0.913\n","test loss : 1.598       accuracy = 0.891\n","epoch :  150  -------------------------------------- \n","train loss : 1.576      accuracy = 0.915\n","test loss : 1.593       accuracy = 0.894\n","epoch :  160  -------------------------------------- \n","train loss : 1.571      accuracy = 0.918\n","test loss : 1.589       accuracy = 0.895\n","epoch :  170  -------------------------------------- \n","train loss : 1.567      accuracy = 0.919\n","test loss : 1.585       accuracy = 0.898\n","epoch :  180  -------------------------------------- \n","train loss : 1.563      accuracy = 0.921\n","test loss : 1.582       accuracy = 0.899\n","epoch :  190  -------------------------------------- \n","train loss : 1.56      accuracy = 0.923\n","test loss : 1.579       accuracy = 0.9\n","epoch :  200  -------------------------------------- \n","train loss : 1.557      accuracy = 0.925\n","test loss : 1.576       accuracy = 0.902\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cYAsmcqw5uZj","executionInfo":{"status":"ok","timestamp":1606311411905,"user_tz":-540,"elapsed":822,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}}},"source":["def gradient_descent_with_scheduler(scheduler, model, optimizer, criterion, batch_size, num_epochs):\n","\n","  # batching\n","  train_loader = torch.utils.data.DataLoader(\n","      data_train,\n","      batch_size=batch_size,\n","      num_workers=2,\n","      shuffle=True,\n","      drop_last=True)\n","  \n","  test_loader = torch.utils.data.DataLoader(\n","      data_test,\n","      batch_size=batch_size,\n","      num_workers=2,\n","      shuffle=False,\n","      drop_last=True)\n","  \n","  \n","  # return variables\n","  train_loss_list, train_acc_list = [], []\n","  test_loss_list, test_acc_list = [], []\n","\n","  \n","  # run training & testing\n","  for epoch in range(num_epochs + 1):\n","\n","    train_loss_avg, train_acc_avg = train(model, criterion, train_loader, optimizer, batch_size)\n","    test_loss_avg, test_acc_avg = test(model, criterion, test_loader, batch_size)\n","    scheduler.step(train_loss_avg)\n","        \n","    # add loss and accuracy data\n","    train_loss_list.append(train_loss_avg)\n","    train_acc_list.append(train_acc_avg)\n","    test_loss_list.append(test_loss_avg)\n","    test_acc_list.append(test_acc_avg)\n","\n","    # print\n","    if epoch % 10 != 0 :\n","      continue\n","\n","    print(\"epoch : \", epoch, \" -------------------------------------- \")\n","    print(\"train loss : {}      accuracy = {}\".format(train_loss_avg, train_acc_avg))\n","    print(\"test loss : {}       accuracy = {}\".format(test_loss_avg, test_acc_avg))\n","\n","\n","  return train_loss_list, train_acc_list, test_loss_list, test_acc_list\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYEVeTEXWFC1","executionInfo":{"status":"ok","timestamp":1606331580076,"user_tz":-540,"elapsed":1958283,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"c5e469a6-91c0-4422-ff06-60ac293c4e55"},"source":["# model\n","model = classification()\n","\n","# mini-batch size\n","batch_size = 32\n","\n","# num of epochs\n","num_epochs = 100\n","\n","# learning rate\n","learning_rate = 0.01\n","\n","# optimizer\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay=0.0001)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.3, verbose=True)   \n","\n","# loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# run\n","train_loss_list8, train_acc_list8, test_loss_list8, test_acc_list8 = gradient_descent_with_scheduler(scheduler, model, optimizer, criterion, batch_size, num_epochs)"],"execution_count":61,"outputs":[{"output_type":"stream","text":["epoch :  0  -------------------------------------- \n","train loss : 0.85      accuracy = 0.72\n","test loss : 0.42       accuracy = 0.88\n","epoch :  10  -------------------------------------- \n","train loss : 0.13      accuracy = 0.95\n","test loss : 0.2       accuracy = 0.94\n","epoch :  20  -------------------------------------- \n","train loss : 0.06      accuracy = 0.97\n","test loss : 0.18       accuracy = 0.95\n","epoch :  30  -------------------------------------- \n","train loss : 0.03      accuracy = 0.98\n","test loss : 0.17       accuracy = 0.95\n","epoch :  40  -------------------------------------- \n","train loss : 0.03      accuracy = 0.99\n","test loss : 0.17       accuracy = 0.95\n","Epoch    51: reducing learning rate of group 0 to 3.0000e-03.\n","epoch :  50  -------------------------------------- \n","train loss : 0.02      accuracy = 0.99\n","test loss : 0.17       accuracy = 0.95\n","epoch :  60  -------------------------------------- \n","train loss : 0.01      accuracy = 0.99\n","test loss : 0.18       accuracy = 0.95\n","Epoch    63: reducing learning rate of group 0 to 9.0000e-04.\n","epoch :  70  -------------------------------------- \n","train loss : 0.01      accuracy = 0.99\n","test loss : 0.18       accuracy = 0.96\n","Epoch    74: reducing learning rate of group 0 to 2.7000e-04.\n","epoch :  80  -------------------------------------- \n","train loss : 0.01      accuracy = 0.99\n","test loss : 0.18       accuracy = 0.96\n","Epoch    85: reducing learning rate of group 0 to 8.1000e-05.\n","epoch :  90  -------------------------------------- \n","train loss : 0.01      accuracy = 0.99\n","test loss : 0.17       accuracy = 0.96\n","Epoch    96: reducing learning rate of group 0 to 2.4300e-05.\n","epoch :  100  -------------------------------------- \n","train loss : 0.01      accuracy = 0.99\n","test loss : 0.17       accuracy = 0.96\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YAv2_J0eW5QZ","executionInfo":{"status":"ok","timestamp":1606317971708,"user_tz":-540,"elapsed":1598294,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"5cc6c7ff-95b7-44ce-f04b-56c37f0c428b"},"source":["# model\n","model = classification()\n","\n","# mini-batch size\n","batch_size = 64\n","\n","# num of epochs\n","num_epochs = 100\n","\n","# learning rate\n","learning_rate = 0.01\n","\n","# optimizer\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay=0.0001)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience = 5, verbose=True)   \n","\n","# loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# run\n","train_loss_list7, train_acc_list7, test_loss_list7, test_acc_list7 = gradient_descent_with_scheduler(scheduler, model, optimizer, criterion, batch_size, num_epochs)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["epoch :  0  -------------------------------------- \n","train loss : 1.84      accuracy = 0.36\n","test loss : 1.25       accuracy = 0.62\n","epoch :  10  -------------------------------------- \n","train loss : 0.24      accuracy = 0.92\n","test loss : 0.25       accuracy = 0.93\n","epoch :  20  -------------------------------------- \n","train loss : 0.15      accuracy = 0.95\n","test loss : 0.2       accuracy = 0.94\n","epoch :  30  -------------------------------------- \n","train loss : 0.11      accuracy = 0.96\n","test loss : 0.18       accuracy = 0.95\n","epoch :  40  -------------------------------------- \n","train loss : 0.08      accuracy = 0.97\n","test loss : 0.18       accuracy = 0.95\n","epoch :  50  -------------------------------------- \n","train loss : 0.06      accuracy = 0.98\n","test loss : 0.17       accuracy = 0.95\n","epoch :  60  -------------------------------------- \n","train loss : 0.05      accuracy = 0.98\n","test loss : 0.17       accuracy = 0.95\n","Epoch    63: reducing learning rate of group 0 to 5.0000e-03.\n","epoch :  70  -------------------------------------- \n","train loss : 0.04      accuracy = 0.98\n","test loss : 0.17       accuracy = 0.95\n","Epoch    72: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch    78: reducing learning rate of group 0 to 1.2500e-03.\n","epoch :  80  -------------------------------------- \n","train loss : 0.04      accuracy = 0.98\n","test loss : 0.17       accuracy = 0.95\n","Epoch    84: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch    90: reducing learning rate of group 0 to 3.1250e-04.\n","epoch :  90  -------------------------------------- \n","train loss : 0.04      accuracy = 0.98\n","test loss : 0.17       accuracy = 0.95\n","Epoch    96: reducing learning rate of group 0 to 1.5625e-04.\n","epoch :  100  -------------------------------------- \n","train loss : 0.04      accuracy = 0.98\n","test loss : 0.17       accuracy = 0.95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iIwxTyMZSVRl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P4vvzguan1BI"},"source":["# 6. Output\n","<hr>"]},{"cell_type":"markdown","metadata":{"id":"BVKRnwMSoE4Y"},"source":["1. Plot the training and testing losses over epochs [2pt]"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"HmOKMxFx0r2u","executionInfo":{"status":"ok","timestamp":1606331611763,"user_tz":-540,"elapsed":945,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"431ecb6c-05fe-4f68-9916-0d016a040cb8"},"source":["plt.title(\"Loss\")\n","plt.plot(train_loss_list8, c = 'red', label = 'train loss')\n","plt.plot(test_loss_list8, c = 'blue', label = 'test loss')\n","plt.legend(loc = 'lower right')\n","plt.show()"],"execution_count":62,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"2kVBxNL4oF7x"},"source":["2. Plot the training and testing accuracies over epochs [2pt]"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"V5SrOJOl0v_d","executionInfo":{"status":"ok","timestamp":1606331619849,"user_tz":-540,"elapsed":1084,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"31a65c18-db16-49ca-9bad-dffc1b01e4d4"},"source":["plt.title(\"Accuracy\")\n","plt.plot(train_acc_list8, c = 'red', label = 'train accuracy')\n","plt.plot(test_acc_list8, c = 'blue', label = 'test accuracy')\n","plt.legend(loc = 'lower right')\n","plt.show()"],"execution_count":63,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"3U9OTAYNoH_e"},"source":["3. Print the final training and testing losses at convergence [2pt]"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"llu1vW6CoJuX","executionInfo":{"status":"ok","timestamp":1606331696504,"user_tz":-540,"elapsed":896,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"e599d942-ec00-40f4-a4f0-fe69316d04e9"},"source":["data1 = {'' : [train_loss_list8[-1], test_loss_list8[-1]]}\n","index1 = ['training', 'testing']\n","frame1 = DataFrame(data1, index = index1)\n","frame1.columns.name = 'loss'\n","frame1"],"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>loss</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>training</th>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>testing</th>\n","      <td>0.17</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["loss          \n","training  0.01\n","testing   0.17"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"markdown","metadata":{"id":"hzYpnpzfoKJb"},"source":["4. Print the final training and testing accuracies at convergence [20pt]"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"MlUVc3-ToLoG","executionInfo":{"status":"ok","timestamp":1606332147166,"user_tz":-540,"elapsed":1506,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"04f839e8-c037-4366-9812-5b3fa899f98b"},"source":["data2 = {'' : [train_acc_list8[-1], test_acc_list8[-1]]}\n","index2 = ['training', 'testing']\n","frame2 = DataFrame(data2, index = index2)\n","frame2.columns.name = 'accuracy'\n","frame2"],"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>accuracy</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>training</th>\n","      <td>0.99</td>\n","    </tr>\n","    <tr>\n","      <th>testing</th>\n","      <td>0.96</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["accuracy      \n","training  0.99\n","testing   0.96"]},"metadata":{"tags":[]},"execution_count":73}]}]}