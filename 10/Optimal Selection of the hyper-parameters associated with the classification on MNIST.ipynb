{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Optimal Selection of the hyper-parameters associated with the classification on MNIST.ipynb","provenance":[],"authorship_tag":"ABX9TyP52ILRpCHm3hU9vWOr3X7T"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"O1305PAEniJS"},"source":["# 0. Setting\n","<hr>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ZjRuljDPm4ML","executionInfo":{"status":"ok","timestamp":1606110284669,"user_tz":-540,"elapsed":784,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"27a21e7c-f7ca-43b6-fa28-e00d5639025b"},"source":["# import library\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import math\n","from pandas import Series, DataFrame\n","import pandas as pd\n","import numpy as np\n","\n","torch.__version__\n"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.7.0+cu101'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"QPJ7yRhanyqJ"},"source":["# 1. Data\n","<hr>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0I9AxJjnzpe","executionInfo":{"status":"ok","timestamp":1606111708791,"user_tz":-540,"elapsed":833,"user":{"displayName":"장예솔","photoUrl":"","userId":"10358588701743689220"}},"outputId":"6996a6e4-900f-461d-9331-1e8163826374"},"source":["from torchvision import transforms, datasets\n","\n","data_path = './MNIST'\n","\n","data_train  = datasets.MNIST(root = data_path, train= False, download=True)\n","data_test = datasets.MNIST(root = data_path, train= True, download=True)\n","\n","data_train_mean = data_train.data.float().mean()/255\n","data_train_std = data_train.data.float().std()/255\n","\n","data_test_mean = data_test.data.float().mean()/255\n","data_test_std = data_test.data.float().std()/255\n","\n","\n","print(\"train data mean = {}, std = {}\".format(data_train_mean, data_train_std))\n","print(\"test data mean = {}, std = {}\".format(data_test_mean, data_test_std))\n","\n","\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((data_train_mean,),(data_train_std,)),\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((data_test_mean,),(data_test_std,)),\n","])\n","\n","data_train  = datasets.MNIST(root = data_path, train= False, download=True, transform= test_transform)\n","data_test   = datasets.MNIST(root = data_path, train= True, download=True, transform= train_transform)\n","\n","print(\"the number of your training data (must be 10,000) = \", data_train.__len__())\n","print(\"hte number of your testing data (must be 60,000) = \", data_test.__len__())\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["train data mean = 0.1325146108865738, std = 0.3104802668094635\n","test data mean = 0.13066047430038452, std = 0.30810779333114624\n","the number of your training data (must be 10,000) =  10000\n","hte number of your testing data (must be 60,000) =  60000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"veKdDvFAoUpW"},"source":[""],"execution_count":null,"outputs":[]}]}